{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgageSzSAAPY"
      },
      "source": [
        "# Gesture Recognition\n",
        "![1607_2716_0 (1)](https://user-images.githubusercontent.com/93203186/172011187-70099885-05f6-4e4a-9dbe-e4db30471f54.jpg)\n",
        "\n",
        "\n",
        "> Imagine working as a data scientist at a home electronics company which manufactures state of the art smart televisions. You want to develop a cool feature in the smart-TV that can recognise five different gestures performed by the user which will help users control the TV without using a remote. \n",
        "> The gestures are continuously monitored by the webcam mounted on the TV. Each gesture corresponds to a specific command:\n",
        "\n",
        "- Thumbs up:  Increase the volume\n",
        "- Thumbs down: Decrease the volume\n",
        "- Left swipe: 'Jump' backwards 10 seconds\n",
        "- Right swipe: 'Jump' forward 10 seconds  \n",
        "- Stop: Pause the movie\n",
        "\n",
        "## Understanding the Dataset\n",
        "> The training data consists of a few hundred videos categorised into one of the five classes. Each video (typically 2-3 seconds long) is divided into a sequence of 30 frames(images). These videos have been recorded by various people performing one of the five gestures in front of a webcam - similar to what the smart TV will use. \n",
        "\n",
        "> The data is in a zip file. The zip file contains a 'train' and a 'val' folder with two CSV files for the two folders. These folders are in turn divided into subfolders where each subfolder represents a video of a particular gesture. Each subfolder, i.e. a video, contains 30 frames (or images). Note that all images in a particular video subfolder have the same dimensions but different videos may have different dimensions. Specifically, videos have two types of dimensions - either 360x360 or 120x160 (depending on the webcam used to record the videos). Hence, you will need to do some pre-processing to standardise the videos. \n",
        "\n",
        "> Each row of the CSV file represents one video and contains three main pieces of information - the name of the subfolder containing the 30 images of the video, the name of the gesture and the numeric label (between 0-4) of the video.\n",
        "\n",
        "> Here task is to train a model on the 'train' folder which performs well on the 'val' folder as well (as usually done in ML projects). We have withheld the test folder for evaluation purposes - your final model's performance will be tested on the 'test' set.\n",
        " \n",
        " ## Goals of this Project\n",
        "\n",
        "> __Generator:__  The generator should be able to take a batch of videos as input without any error. Steps like cropping, resizing and normalization should be performed successfully.\n",
        "\n",
        "> __Model:__ Develop a model that is able to train without any errors which will be judged on the total number of parameters (as the inference(prediction) time should be less) and the accuracy achieved.\n",
        "\n",
        "> __Write up:__ This should contain the detailed procedure followed in choosing the final model. The write up should start with the reason for choosing the base model, then highlight the reasons and metrics taken into consideration to modify and experiment to arrive at the final model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sfT2tANNYBl"
      },
      "source": [
        "### Attention\n",
        "\n",
        "- Few models could result in Resourse exhuasted error (OOM error), in this situation kindly reset kernel and restart same notebook followed by running required cell of respective model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HV1B24qwAAPh"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import os\n",
        "from skimage.transform import resize\n",
        "from imageio import imread\n",
        "import datetime\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import abc\n",
        "from sys import getsizeof"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AqvzO1kXAAPk"
      },
      "outputs": [],
      "source": [
        "# We set the random seed so that the results don't vary drastically.\n",
        "\n",
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6on9TJ1AAPl"
      },
      "source": [
        "## Loading Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP1twuOdAnTy"
      },
      "source": [
        "# Creating Pipline from gmail drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## If we are using the data by mounting the google drive, we use the following code:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ_wEHcTNstE",
        "outputId": "9644418e-a03c-49ea-9966-a1cd260ce959"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieEq_sStnbSQ"
      },
      "source": [
        "In this cell below, we read the folder names for training and validation. We also set the `batch_size` here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xCmQ4vKvAAPm"
      },
      "outputs": [],
      "source": [
        "train_doc = np.random.permutation(open('/content/gdrive/MyDrive/Project_data/train.csv').readlines())\n",
        "val_doc = np.random.permutation(open('/content/gdrive/MyDrive/Project_data/val.csv').readlines())\n",
        "batch_size = 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcV1ThlhAAPn"
      },
      "source": [
        "## Generator\n",
        "\n",
        "This is one of the most important part of the code. The overall structure of the generator has been given here. In the generator, we are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. (We can experiment with `img_idx`, `y`,`z` and normalization until we can get high accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RhiT_22XZ8UG"
      },
      "outputs": [],
      "source": [
        "# coding to crop and Resize of photosimages\n",
        "def cropAndResize(image,HEIGHT_DIMENSION,WIDTH_DIMENSION):\n",
        "    #crop the images and resize them.  \n",
        "    #Note that the images are of 2 different shape& the conv3D will throw error if the inputs in a batch have different shapes.\n",
        "    # CROPPING (making aspect ratio same)\n",
        "    if abs(image.shape[0]-image.shape[1])%2==0 and image.shape[0]!=image.shape[1]:\n",
        "        dimension_diff=abs(image.shape[0]-image.shape[1])\n",
        "        cropping_ratio=dimension_diff//2\n",
        "        if image.shape[0]>image.shape[1]:\n",
        "            image=image[cropping_ratio:image.shape[0]-cropping_ratio,:,:]\n",
        "        elif image.shape[0]<image.shape[1]:\n",
        "            image=image[:,cropping_ratio:image.shape[1]-cropping_ratio,:]\n",
        "                    \n",
        "    # RESIZING\n",
        "    if image.shape[0]>120 or image.shape[1]>120:\n",
        "        image=resize(image, (120, 120))\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n1DsomEkAAPq"
      },
      "outputs": [],
      "source": [
        "# Defininng Generator function\n",
        "def generator(source_path, folder_list, batch_size):\n",
        "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
        "    img_idx = 7,9,10,11,12,13,14,15,16,17,18,19,20,21,22,24 #create a list of image no's you want to use for a particular video\n",
        "    while True:\n",
        "        t = np.random.permutation(folder_list)\n",
        "        num_batches = len(t)//batch_size                 # calculate the number of batches\n",
        "        remaining_batch_size=len(t)%batch_size\n",
        "        for batch in range(num_batches):                 # we iterate over the number of batches\n",
        "            batch_data = np.zeros((batch_size,16,120,120,3)) # x is the no. of images you use for each video,(y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((batch_size,5))      # batch_labels is the one hot representation of the output\n",
        "            for folder in range(batch_size):             # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # Read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx):      # Iterate over the frames/images of a folder to read them in\n",
        "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                    image_resized = cropAndResize(image,120,120)                    \n",
        "                    batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255         # Normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255         # Normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255         # Normalise and feed in the image\n",
        "                    \n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            yield batch_data, batch_labels                # you yield the batch_data and the batch_labels\n",
        "        for batch in range(num_batches,num_batches+1):    # iterate over the number of batches\n",
        "            batch_data = np.zeros((remaining_batch_size*2,16,120,120,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((remaining_batch_size*2,5))       # batch_labels is the one hot representation of the output\n",
        "            for folder in range(remaining_batch_size):                # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                    image_resized = cropAndResize(image,120,120)                    \n",
        "                    batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255        #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255        #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255        #normalise and feed in the image\n",
        "                    \n",
        "                    # code for the remaining data points which are left after full batches\n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            yield batch_data, batch_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "duB78bvpAAPs"
      },
      "outputs": [],
      "source": [
        "# Creating fuction for plotting results in graph\n",
        "from matplotlib import pyplot as plt\n",
        "def plot(history):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
        "    axes[0].plot(history.history['loss'])   \n",
        "    axes[0].plot(history.history['val_loss'])\n",
        "    axes[0].legend(['loss','val_loss'])\n",
        "\n",
        "    axes[1].plot(history.history['categorical_accuracy'])   \n",
        "    axes[1].plot(history.history['val_categorical_accuracy'])\n",
        "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNkgEzXNAAPt",
        "outputId": "eabb9eb2-4d11-48a0-9e2c-1ceef649c279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sequences = 663\n",
            "Validation sequences = 100\n",
            "Epochs = 15\n"
          ]
        }
      ],
      "source": [
        "curr_dt_time = datetime.datetime.now()\n",
        "train_path = '/content/gdrive/MyDrive/Project_data/train'\n",
        "val_path = '/content/gdrive/MyDrive/Project_data/val'\n",
        "num_train_sequences = len(train_doc)\n",
        "print('Training sequences =', num_train_sequences)\n",
        "num_val_sequences = len(val_doc)\n",
        "print('Validation sequences =', num_val_sequences)\n",
        "num_epochs = 15              # choose the number of epochs\n",
        "print ('Epochs =', num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WUnbIBqAAPu"
      },
      "source": [
        "## Model\n",
        "\n",
        "Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Kg5IRVosAAPu"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation,Dropout,GlobalAveragePooling3D,LSTM,GlobalAveragePooling2D\n",
        "from keras.layers.convolutional import Conv3D, MaxPooling3D,Conv2D,MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau,EarlyStopping\n",
        "from keras import optimizers\n",
        "img_idx = 7,9,10,11,12,13,14,15,16,17,18,19,20,21,22,24\n",
        "input_shape = (len(img_idx), 120, 120, 3)\n",
        "np.random.seed(30)\n",
        "\n",
        "# These two steps are common for all 10 models. Make sure to run this cell before fitting any model after kernel reset\n",
        "\n",
        "# create the `train_generator` and the `val_generator` which is used in `.fit_generator`.\n",
        "\n",
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)\n",
        "\n",
        "#defining steps per epoch\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xvZo9j0AAPv"
      },
      "source": [
        "### 1st Model : Simple Conv3D\n",
        "### with Batch size = 40, No's of epoch = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MtYgigrUAAPv"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling3D(pool_size=2))\n",
        "\n",
        "model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apCFn4NmAAPw"
      },
      "source": [
        "1. In next  `train_generator` and the `val_generator` which is defined, as it has to be used in `.fit_generator`.\n",
        "2. The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make. These are also defined in cell below\n",
        "3. After the model creation in above cell, the next step is to `compile` the model followed by 1st and 2nd step. In the `summary` of the model, we'll see the total number of parameters to train.\n",
        "\n",
        "These steps are same for all the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oH8iCvAKzsY",
        "outputId": "43537556-2ab2-4f7b-f8cc-348be4057b6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 14, 118, 118, 32)  2624      \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 7, 59, 59, 32)    0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 5, 57, 57, 64)     55360     \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPooling  (None, 2, 28, 28, 64)    0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               25690368  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,749,637\n",
            "Trainable params: 25,749,637\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# create the `train_generator` and the `val_generator` which is used in `.fit_generator`.\n",
        "\n",
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)\n",
        "\n",
        "num_epochs = 10              # choose the number of epochs\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "LR =ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4) # write the REducelronplateau code here\n",
        "earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
        "callbacks_list = [checkpoint, LR, earlystop]\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "    \n",
        "optimiser =tf.keras.optimizers.Adam() #write your optimizer\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_joHaloAAPw"
      },
      "source": [
        "\n",
        "Now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQa1YT3fAAPx",
        "outputId": "b1df510a-54db-49e7-d919-aa621d6d792a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source path =  /content/gdrive/MyDrive/Project_data/train ; batch size = 40\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvMxLdEcNCzl"
      },
      "outputs": [],
      "source": [
        "plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiS_yEhFNYBy"
      },
      "source": [
        "### Model 1 Output says:\n",
        "- categorical_accuracy: 0.8907  \n",
        "- val_categorical_accuracy: 0.5417\n",
        "\n",
        "Model is overfit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCMiw-kFAAPx"
      },
      "source": [
        "### 2nd Model : Conv3D with BatchNormalization\n",
        "### here Batch size = 40, No of epoch = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqK3t5CRAAPx"
      },
      "outputs": [],
      "source": [
        " model = Sequential()\n",
        "\n",
        " model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        " model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
        " model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        " model.add(BatchNormalization())\n",
        "\n",
        " model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
        " model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        " model.add(BatchNormalization())\n",
        "\n",
        " model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
        " model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
        " model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
        " model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        " model.add(BatchNormalization())\n",
        "\n",
        " model.add(Flatten())\n",
        " model.add(Dense(512, activation='relu'))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbyIvTSCNPGZ"
      },
      "outputs": [],
      "source": [
        "num_epochs = 15              # choose the number of epochs\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "LR =ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4) # write the REducelronplateau code here\n",
        "earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
        "callbacks_list = [checkpoint, LR, earlystop]\n",
        "\n",
        "optimiser =tf.keras.optimizers.Adam() #write your optimizer\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMGy3jPZAAPy"
      },
      "outputs": [],
      "source": [
        "history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_q5iW5K84ox"
      },
      "outputs": [],
      "source": [
        "plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk_0fdxxNYB1"
      },
      "source": [
        "### Model 2 Output says:\n",
        "- categorical_accuracy: 0.9927  \n",
        "- val_categorical_accuracy: 0.2250\n",
        "\n",
        "Model is early stopping as accuracy is not increasing with each consistnet epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COsmXUPqAAPz"
      },
      "source": [
        "### 3rd Model : Conv3D with BatchNormalization and Dropout\n",
        "### here batch_size = 40, No of epoch = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvG8vHYuAAPz"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
        "model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omtw4m6Zg3Xf"
      },
      "outputs": [],
      "source": [
        "num_epochs = 20              # choose the number of epochs\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "LR =ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4) # write the REducelronplateau code here\n",
        "earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
        "callbacks_list = [checkpoint, LR, earlystop]\n",
        "\n",
        "optimiser =tf.keras.optimizers.Adam() #write your optimizer\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQdCRAegAAP0"
      },
      "outputs": [],
      "source": [
        "history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVgHyysFhIsd"
      },
      "source": [
        "plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8M2KWhDNYB3"
      },
      "source": [
        "### Model 3 Output says:\n",
        "- categorical_accuracy: 0.9431  \n",
        "- val_categorical_accuracy: 0.1667\n",
        "\n",
        "Model is early stopping as accuracy is not increasing with each consistnet epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maTdnlhFAAP0"
      },
      "source": [
        "### 4th Model: Conv3D with BatchNormalization,Dropout and GlobalAveragePooling\n",
        "### batch_size=40,epoch=30      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ispPOztBAAP0"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(GlobalAveragePooling3D())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0-OmTUwhmlc"
      },
      "outputs": [],
      "source": [
        "num_epochs = 30              # choose the number of epochs\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "LR =ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4) # write the REducelronplateau code here\n",
        "earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
        "callbacks_list = [checkpoint, LR, earlystop]\n",
        "\n",
        "optimiser =tf.keras.optimizers.Adam() #write your optimizer\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3TVEnLiAAP1"
      },
      "outputs": [],
      "source": [
        "history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bckqI6LzAAP1"
      },
      "outputs": [],
      "source": [
        " plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-OXJL4FNYB9"
      },
      "source": [
        "### Model 4 Output says:\n",
        "- categorical_accuracy: 0.9052  \n",
        "- val_categorical_accuracy: 0.1917\n",
        "\n",
        "Model is early stopping as accuracy is not increasing with each consistnet epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcoKkxjXAAP2"
      },
      "source": [
        "### 5th Model: Conv 2D and LSTM\n",
        "### here Batch_size=40, No of epoch = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVY_B7KiAAP2"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(TimeDistributed(Conv2D(32, (3,3), activation='relu'), input_shape=input_shape))\n",
        "model.add(TimeDistributed(MaxPooling2D((2,2))))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(TimeDistributed(Conv2D(64, (3,3), activation='relu')))\n",
        "model.add(TimeDistributed(MaxPooling2D((2,2))))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
        "model.add(TimeDistributed(Dense(64, activation='relu')))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(128))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tOEtt3-hbi-"
      },
      "outputs": [],
      "source": [
        "num_epochs = 40              # choose the number of epochs\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "LR =ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4) # write the REducelronplateau code here\n",
        "earlystop = EarlyStopping( monitor=\"val_categorical_accuracy\",mode='max',patience=10,verbose=1)\n",
        "callbacks_list = [checkpoint, LR, earlystop]\n",
        "\n",
        "optimiser =tf.keras.optimizers.Adam() #write your optimizer\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_mKuNNLAAP2"
      },
      "outputs": [],
      "source": [
        " history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyxBpsGMAAP3"
      },
      "outputs": [],
      "source": [
        "plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM2473FyNYCA"
      },
      "source": [
        "### Model 5 Output says:\n",
        "- categorical_accuracy: 0.8455  \n",
        "- val_categorical_accuracy: 0.1500\n",
        "\n",
        "Model is early stopping as accuracy is not increasing with each consistnet epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgzywbamAAP3"
      },
      "source": [
        "### 6th Model: Conv2D + GRU\n",
        "### here Batch_size = 40, No of epoch = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_SCW-lKAAP4"
      },
      "outputs": [],
      "source": [
        " model = Sequential()\n",
        " model.add(TimeDistributed(Conv2D(32, (3,3), activation='relu'), input_shape=input_shape))\n",
        " model.add(TimeDistributed(MaxPooling2D((2,2))))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dropout(0.2))\n",
        "\n",
        " model.add(TimeDistributed(Conv2D(64, (3,3), activation='relu')))\n",
        " model.add(TimeDistributed(MaxPooling2D((2,2))))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dropout(0.2))\n",
        "\n",
        " model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
        " model.add(TimeDistributed(Dense(64, activation='relu')))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dropout(0.2))\n",
        "\n",
        " model.add(GRU(128))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gk_OFqcch4N0"
      },
      "outputs": [],
      "source": [
        "num_epochs = 40              # choose the number of epochs\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "LR =ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4) # write the REducelronplateau code here\n",
        "earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
        "callbacks_list = [checkpoint, LR, earlystop]\n",
        "\n",
        "optimiser =tf.keras.optimizers.Adam() #write your optimizer\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlWZ-xVcAAP4",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        " history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAR5LVItAAP5"
      },
      "outputs": [],
      "source": [
        " plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enYlkylENYCB"
      },
      "source": [
        "### Model 6 Output says:\n",
        "- categorical_accuracy: 0.8688  \n",
        "- val_categorical_accuracy: 0.5417\n",
        "\n",
        "Model is overfit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMVyR1_pAAP5"
      },
      "source": [
        "### 7th Model: TransferLearning (VGG16) + LSTM\n",
        "### here Batch_size = 40, No of epoch = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZApMheVAAP5"
      },
      "outputs": [],
      "source": [
        " from keras.applications.vgg16 import VGG16\n",
        " VGG16_transfer = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False)\n",
        " model = Sequential()\n",
        " model.add(TimeDistributed(VGG16_transfer,input_shape=input_shape))\n",
        " for layer in model.layers:\n",
        "     layer.trainable = False\n",
        "\n",
        " model.add(TimeDistributed(BatchNormalization()))\n",
        " model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        " model.add(TimeDistributed(Flatten()))\n",
        " model.add(LSTM(128))\n",
        " model.add(Dropout(0.25))\n",
        " model.add(Dense(64,activation='relu'))\n",
        " model.add(Dropout(0.25))\n",
        "       \n",
        " model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIVABOjEiDmb"
      },
      "outputs": [],
      "source": [
        "num_epochs = 30              # choose the number of epochs\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "LR =ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4) # write the REducelronplateau code here\n",
        "earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
        "callbacks_list = [checkpoint, LR, earlystop]\n",
        "\n",
        "optimiser =tf.keras.optimizers.Adam() #write your optimizer\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jaVtPr9AAP6",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gp9O7O1a8fIS"
      },
      "outputs": [],
      "source": [
        "plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdAkzRm-NYCD"
      },
      "source": [
        "### Model 7 Output says:\n",
        "- categorical_accuracy: 0.9665  \n",
        "- val_categorical_accuracy: 0.4667\n",
        "\n",
        "Model is overfit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDuRt7XAAAP6"
      },
      "source": [
        "### 8th Model: VGG16 + LSTM with BatchNormalization\n",
        "### here batch_size=40, No of epoch = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zBkS93kAAP7"
      },
      "outputs": [],
      "source": [
        " from keras.applications.vgg16 import VGG16\n",
        " VGG16_transfer = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False)\n",
        " model = Sequential()\n",
        " model.add(TimeDistributed(VGG16_transfer,input_shape=input_shape))\n",
        " for layer in model.layers:\n",
        "     layer.trainable = False\n",
        "\n",
        " model.add(TimeDistributed(BatchNormalization()))\n",
        " model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        " model.add(TimeDistributed(Flatten()))\n",
        " model.add(LSTM(128))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dense(64,activation='relu'))\n",
        " model.add(Dropout(0.25))\n",
        "        \n",
        " model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UldOOy5ciMHD"
      },
      "outputs": [],
      "source": [
        "num_epochs = 30              # choose the number of epochs\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "LR =ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4) # write the REducelronplateau code here\n",
        "earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
        "callbacks_list = [checkpoint, LR, earlystop]\n",
        "\n",
        "optimiser =tf.keras.optimizers.Adam() #write your optimizer\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBmohxaaAAP7",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        " history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6NiQhblAAP8"
      },
      "outputs": [],
      "source": [
        "plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ictX7ZwkNYCF"
      },
      "source": [
        "### Model 8 Output says:\n",
        "- categorical_accuracy: 0.9723  \n",
        "- val_categorical_accuracy: 0.6167\n",
        "\n",
        "Model is still overfit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn9Ry5xIAAP8"
      },
      "source": [
        "### 9th Model: VGG16 + GRU\n",
        "### here batch_size=40, No of epoch = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XNfPIOzAAP8"
      },
      "outputs": [],
      "source": [
        " from keras.applications.vgg16 import VGG16\n",
        " VGG16_transfer = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False)\n",
        " model = Sequential()\n",
        " model.add(TimeDistributed(VGG16_transfer,input_shape=input_shape))\n",
        " for layer in model.layers:\n",
        "     layer.trainable = False\n",
        "\n",
        " model.add(TimeDistributed(BatchNormalization()))\n",
        " model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        " model.add(TimeDistributed(Flatten()))\n",
        " model.add(GRU(128))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dropout(0.5))\n",
        " model.add(Dense(64,activation='relu'))\n",
        " model.add(Dropout(0.5))\n",
        "        \n",
        " model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bv9hqhKGiTvU"
      },
      "outputs": [],
      "source": [
        "num_epochs = 20              # choose the number of epochs\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "LR =ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4) # write the REducelronplateau code here\n",
        "earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
        "callbacks_list = [checkpoint, LR, earlystop]\n",
        "\n",
        "optimiser =tf.keras.optimizers.Adam() #write your optimizer\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5iRPsKoAAP9"
      },
      "outputs": [],
      "source": [
        "history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                     callbacks=callbacks_list, validation_data=val_generator, \n",
        "                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPlSjDDYAAP9"
      },
      "outputs": [],
      "source": [
        " plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlO0bG8aNYCI"
      },
      "source": [
        "### Model 9 Output says:\n",
        "- categorical_accuracy: 0.8921  \n",
        "- val_categorical_accuracy: 0.5417\n",
        "\n",
        "Model is overfit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGIS5BWKAAP9"
      },
      "source": [
        "## 10th Model: TransferLearning(Mobilenet) + GRU\n",
        "### here batch size = 40, No of epoch = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K26tmkGuAAP-"
      },
      "outputs": [],
      "source": [
        "from keras.applications import mobilenet\n",
        "\n",
        "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(TimeDistributed(mobilenet_transfer,input_shape=input_shape))\n",
        " \n",
        "model.add(TimeDistributed(BatchNormalization()))\n",
        "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "model.add(GRU(128))\n",
        "model.add(Dropout(0.25))\n",
        "        \n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "        \n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aq0Rs5vhAAP-"
      },
      "outputs": [],
      "source": [
        "num_epochs = 15              # choose the number of epochs\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "LR =ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4) # write the REducelronplateau code here\n",
        "earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
        "callbacks_list = [checkpoint, LR, earlystop]\n",
        "\n",
        "optimiser =tf.keras.optimizers.Adam() #write your optimizer\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiUAAV1NAAQA"
      },
      "outputs": [],
      "source": [
        "history=model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSHw6cyqAAQA"
      },
      "source": [
        "### View Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj0aqS7iAAQA"
      },
      "outputs": [],
      "source": [
        "plot(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3Xy7Pj0AAQB"
      },
      "source": [
        "### Conclusion:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_yJBFieAAQB"
      },
      "source": [
        "### Model 10 Output says:\n",
        "- categorical_accuracy: 0.9694  \n",
        "- val_categorical_accuracy: 0.9333\n",
        "\n",
        "Model is robust.\n",
        "With different learning method, change in different no of epoch and training parameters from that Model 10 (Mobilenet + GRU) gave best accuracy when compared to all above models.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Gesture_Recognition_Durgesh_Chaubey (1).ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}